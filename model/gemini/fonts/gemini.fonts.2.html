<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KaTeX & Font Pairing: Heavy Content Test</title>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,600;1,400&family=Inter:wght@400;500;600&family=Lato:wght@400;700&family=Montserrat:wght@400;500;600&family=Open+Sans:wght@400;600&family=Roboto:wght@400;500&family=Source+Sans+3:wght@400;600&display=swap"
        rel="stylesheet">

    <style>
        /* Global Page Styling */
        body {
            background-color: #f0f2f5;
            color: #222;
            margin: 0;
            padding: 60px 20px;
            line-height: 1.7;
            /* Increased for better readability */
        }

        h1 {
            font-family: 'Inter', sans-serif;
            text-align: center;
            margin-bottom: 60px;
            color: #111;
            letter-spacing: -0.03em;
            font-weight: 800;
            font-size: 2.5rem;
        }

        /* Card Container Styling */
        .font-card {
            background: white;
            max-width: 900px;
            margin: 0 auto 60px auto;
            padding: 50px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.06);
            border-left: 8px solid #444;
        }

        .label {
            text-transform: uppercase;
            letter-spacing: 1.5px;
            font-size: 0.75rem;
            color: #888;
            font-family: sans-serif;
            margin-bottom: 20px;
            display: block;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
            font-weight: 600;
        }

        h2 {
            margin-top: 0;
            margin-bottom: 1.5rem;
            font-size: 1.75rem;
        }

        p {
            margin-bottom: 1.5rem;
        }

        /* Math spacing */
        .katex-display {
            margin: 2em 0;
            overflow-x: auto;
            overflow-y: hidden;
        }

        /* --- THE FONT STYLES --- */

        /* 1. Khan Academy Style: Lato */
        .style-khan {
            font-family: 'Lato', sans-serif;
            border-left-color: #14bf96;
            color: #333;
        }

        /* 2. Stack Exchange Style: Arial */
        .style-stack {
            font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
            border-left-color: #f48024;
            font-size: 15px;
            line-height: 1.5;
        }

        /* 3. Brilliant.org Style: Inter */
        .style-brilliant {
            font-family: 'Inter', sans-serif;
            border-left-color: #222;
            color: #1a1a1a;
        }

        /* 4. Wikipedia Style: Sans-Serif Generic */
        .style-wiki {
            font-family: sans-serif;
            border-left-color: #666;
            line-height: 1.6;
        }

        /* 5. WolframAlpha Style: Verdana */
        .style-wolfram {
            font-family: Verdana, sans-serif;
            font-size: 0.95rem;
            border-left-color: #ff7e00;
        }

        /* 6. Overleaf Style: Montserrat */
        .style-overleaf {
            font-family: 'Montserrat', sans-serif;
            border-left-color: #47a141;
        }

        /* 7. ArXiv Style: Open Sans */
        .style-arxiv {
            font-family: 'Open Sans', sans-serif;
            border-left-color: #b31b1b;
        }

        /* 8. Coursera Style: Source Sans 3 */
        .style-coursera {
            font-family: 'Source Sans 3', sans-serif;
            border-left-color: #0056D2;
        }

        /* 9. LibreTexts Style: Roboto */
        .style-libre {
            font-family: 'Roboto', sans-serif;
            border-left-color: #f7b731;
        }

        /* 10. The Professor: Bitter (Serif) */
        .style-serif {
            font-family: 'Bitter', serif;
            border-left-color: #444;
            font-size: 1.1rem;
        }

        /* 11. NEXT.JS STYLE */
        .style-next {
            font-family: 'Inter', sans-serif;
            letter-spacing: -0.025em;
            /* Tighter tracking */
            color: #000;
            border-left-color: #000;
        }

        .style-next h2 {
            font-weight: 700;
            letter-spacing: -0.04em;
        }

        /* 12. CLERK.COM STYLE */
        .style-clerk {
            font-family: 'Inter', sans-serif;
            color: #1c1c1e;
            border-left-color: #6c47ff;
            /* Clerk Purple */
        }

        .style-clerk h2 {
            font-weight: 600;
            color: #2e2e33;
        }
    </style>
</head>

<body>

    <h1>Math & Font Pairing: Full Content Test</h1>

    <div class="font-card style-khan">
        <span class="label">Style: Khan Academy (Font: Lato)</span>
        <h2>Calculus: The Chain Rule & Composite Functions</h2>
        <p>
            Welcome back. In this lesson, we are going to dive deep into how to differentiate composite functions.
            Imagine you have a function nested inside another function, like a set of Russian dolls. If we let \( h(x) =
            f(g(x)) \), we cannot just take the derivative of the outside function and ignore the inside. We have to
            apply the <strong>Chain Rule</strong>, which tells us to peel the layers one by one.
        </p>
        <p>
            The formal definition of the chain rule states that if \( g \) is differentiable at \( x \) and \( f \) is
            differentiable at \( g(x) \), then the composite function \( h \) is differentiable at \( x \), and its
            derivative is given by the product of the outer derivative and the inner derivative:
            $$ h'(x) = \frac{d}{dx}f(g(x)) = f'(g(x)) \cdot g'(x) $$
        </p>
        <p>
            Let's try a concrete, multi-step example to see this in action. Suppose we want to find the derivative of \(
            y = \sin^3(4x^2 - 1) \). This is actually a three-layer function! We have the cube function on the outside,
            the sine function in the middle, and the polynomial \( 4x^2 - 1 \) on the inside.
        </p>
        <p>
            Let \( u = \sin(4x^2 - 1) \). Then \( y = u^3 \).
            <br>
            Let \( v = 4x^2 - 1 \). Then \( u = \sin(v) \).
            <br>
            Now apply the chain rule iteratively:
            $$ \begin{aligned}
            \frac{dy}{dx} &= \frac{dy}{du} \cdot \frac{du}{dv} \cdot \frac{dv}{dx} \\
            &= \frac{d}{du}(u^3) \cdot \frac{d}{dv}(\sin v) \cdot \frac{d}{dx}(4x^2 - 1) \\
            &= (3u^2) \cdot (\cos v) \cdot (8x) \\
            &= 3\sin^2(4x^2 - 1) \cdot \cos(4x^2 - 1) \cdot 8x \\
            &= 24x \sin^2(4x^2 - 1) \cos(4x^2 - 1)
            \end{aligned} $$
        </p>
        <p>
            Notice how we kept the inner arguments exactly the same until the very end? We treated \( \sin(v) \) as just
            a block while differentiating the cube, and we treated \( 4x^2-1 \) as a block while differentiating the
            sine. This pattern appears everywhere in calculus, especially in physics when dealing with time-dependent
            harmonic motion.
        </p>
    </div>

    <div class="font-card style-stack">
        <span class="label">Style: Stack Exchange (Font: Arial)</span>
        <h2>Linear Algebra: Issues Diagonalizing a 3x3 Matrix</h2>
        <p>
            I am working on a problem from my linear algebra textbook regarding spectral decomposition, and I'm hitting
            a wall with the algebraic simplification. The goal is to find the eigenvalues and eigenvectors for matrix \(
            A \), and then write it in the form \( PDP^{-1} \).
        </p>
        <p>
            Here is the matrix I am working with:
            $$ A = \begin{pmatrix} 2 & 0 & 0 \\ 1 & 2 & 1 \\ -1 & 0 & 1 \end{pmatrix} $$
        </p>
        <p>
            I started by setting up the characteristic equation \( \det(A - \lambda I) = 0 \). Expanding along the first
            row seems the easiest path:
            $$ \begin{aligned}
            \det(A - \lambda I) &= \det \begin{pmatrix} 2-\lambda & 0 & 0 \\ 1 & 2-\lambda & 1 \\ -1 & 0 & 1-\lambda
            \end{pmatrix} \\
            &= (2-\lambda) \cdot \det \begin{pmatrix} 2-\lambda & 1 \\ 0 & 1-\lambda \end{pmatrix} - 0 + 0 \\
            &= (2-\lambda) \left[ (2-\lambda)(1-\lambda) - (1)(0) \right] \\
            &= (2-\lambda)^2 (1-\lambda)
            \end{aligned} $$
        </p>
        <p>
            So, the eigenvalues are \( \lambda = 1 \) (algebraic multiplicity 1) and \( \lambda = 2 \) (algebraic
            multiplicity 2).
        </p>
        <p>
            My issue is finding the eigenvectors for \( \lambda = 2 \). When I solve \( (A - 2I)\mathbf{v} = 0 \):
            $$ \begin{pmatrix} 0 & 0 & 0 \\ 1 & 0 & 1 \\ -1 & 0 & -1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3
            \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} $$
        </p>
        <p>
            This gives the equation \( x_1 + x_3 = 0 \implies x_1 = -x_3 \). The variable \( x_2 \) is free. Does this
            mean I have two linearly independent eigenvectors, such as \( \mathbf{v}_1 = (0, 1, 0)^T \) and \(
            \mathbf{v}_2 = (-1, 0, 1)^T \)? If so, is the matrix diagonalizable despite the zero row in the reduced
            form? Any help verifying my basis vectors would be appreciated.
        </p>
    </div>

    <div class="font-card style-brilliant">
        <span class="label">Style: Brilliant.org (Font: Inter)</span>
        <h2>Concept: Bayes' Theorem & Conditional Probability</h2>
        <p>
            Our intuition about probability is often wrong. We tend to confuse the <em>probability of a cause given an
                effect</em> with the <em>probability of an effect given a cause</em>. Bayes' Theorem provides the
            rigorous mathematical framework to update our beliefs when we receive new evidence.
        </p>
        <p>
            Mathematically, for two events \( A \) and \( B \), the theorem connects the conditional probabilities:
            $$ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} $$
        </p>
        <p>
            <strong>The Medical Test Paradox</strong><br>
            Imagine a rare disease that affects only 1% of the population (\( P(D) = 0.01 \)). You take a test that is
            99% accurate. This means if you have the disease, it tests positive 99% of the time (\( P(+|D) = 0.99 \)),
            and if you don't, it tests negative 99% of the time (\( P(-|D^c) = 0.99 \)).
        </p>
        <p>
            You test positive. What is the chance you actually have the disease? Most people intuitively guess 99%.
            Let's calculate the true probability \( P(D|+) \) using the Law of Total Probability for the denominator:
            $$ \begin{aligned}
            P(D|+) &= \frac{P(+|D)P(D)}{P(+|D)P(D) + P(+|D^c)P(D^c)} \\
            &= \frac{(0.99)(0.01)}{(0.99)(0.01) + (0.01)(0.99)} \\
            &= \frac{0.0099}{0.0099 + 0.0099} \\
            &= \frac{0.0099}{0.0198} = 0.5
            \end{aligned} $$
        </p>
        <p>
            Surprisingly, the answer is only <strong>50%</strong>. Because the disease is so rare, the sheer number of
            "false positives" coming from the large healthy population matches the number of "true positives" from the
            tiny sick population. This example illustrates why clean, geometric fonts like Inter are essential for
            parsing logic—they strip away visual distraction so you can focus on the counter-intuitive result.
        </p>
    </div>

    <div class="font-card style-wiki">
        <span class="label">Style: Wikipedia (Font: Sans-Serif)</span>
        <h2>Navier–Stokes Equations</h2>
        <p>
            The <strong>Navier–Stokes equations</strong> are a set of partial differential equations which describe the
            motion of viscous fluid substances. Use of the Navier–Stokes equations usually begins with the definition of
            the fluid properties (such as density, viscosity, and thermal conductivity) and the boundary conditions of
            the domain of interest. They are the foundation of fluid mechanics.
        </p>
        <p>
            In an inertial frame of reference, the general form of the equations of fluid motion is derived from
            Newton's second law:
            $$ \rho \left( \frac{\partial \mathbf{u}}{\partial t} + \mathbf{u} \cdot \nabla \mathbf{u} \right) = -\nabla
            p + \nabla \cdot \left[ \mu (\nabla \mathbf{u} + (\nabla \mathbf{u})^T) \right] + \mathbf{f} $$
        </p>
        <p>
            Where the variables are defined as:
        <ul>
            <li>\( \mathbf{u} \) is the fluid velocity vector field</li>
            <li>\( p \) is the fluid pressure field</li>
            <li>\( \rho \) is the fluid density</li>
            <li>\( \mu \) is the dynamic viscosity</li>
            <li>\( \mathbf{f} \) represents external body forces (like gravity)</li>
        </ul>
        </p>
        <p>
            For the specific case of an <strong>incompressible Newtonian fluid</strong> (where density \( \rho \) is
            constant and divergence is zero), the equations simplify. The continuity equation becomes \( \nabla \cdot
            \mathbf{u} = 0 \), and the momentum equation reduces to:
            $$ \frac{\partial \mathbf{u}}{\partial t} + (\mathbf{u} \cdot \nabla)\mathbf{u} - \nu \nabla^2 \mathbf{u} =
            -\frac{1}{\rho}\nabla p + \mathbf{g} $$
        </p>
        <p>
            Despite their wide use in modeling weather, ocean currents, and air flow over wings, rigorous mathematical
            proof of the existence and smoothness of solutions in three dimensions remains one of the seven
            <em>Millennium Prize Problems</em>, with a prize of $1 million.
        </p>
    </div>

    <div class="font-card style-wolfram">
        <span class="label">Style: WolframAlpha (Font: Verdana)</span>
        <h2>Input: Definite Integral Computation</h2>
        <p>
            <strong>Input interpretation:</strong><br>
            Compute the definite integral of the function \( x^2 e^{-x} \) from zero to infinity.
            $$ \int_{0}^{\infty} x^2 e^{-x} \, dx $$
        </p>
        <p>
            <strong>Step-by-step solution:</strong><br>
            We can solve this using integration by parts, where \( \int u \, dv = uv - \int v \, du \). Let \( u = x^2
            \) and \( dv = e^{-x}dx \). Then \( du = 2x \, dx \) and \( v = -e^{-x} \).
        </p>
        <p>
            First iteration:
            $$ \begin{aligned}
            \int x^2 e^{-x} \, dx &= -x^2 e^{-x} - \int -2x e^{-x} \, dx \\
            &= -x^2 e^{-x} + 2 \int x e^{-x} \, dx
            \end{aligned} $$
            Now we must perform integration by parts a second time on the remaining integral \( \int x e^{-x} \, dx \):
            $$ \begin{aligned}
            \int x e^{-x} \, dx &= -x e^{-x} - \int -e^{-x} \, dx \\
            &= -x e^{-x} - e^{-x}
            \end{aligned} $$
        </p>
        <p>
            <strong>Result:</strong><br>
            Combining these terms and evaluating the limits from \( 0 \) to \( \infty \). Note that as \( x \to \infty
            \), the exponential term dominates the polynomial term, driving the value to 0.
            $$ \left[ -e^{-x}(x^2 + 2x + 2) \right]_0^{\infty} = 0 - (-1)(0 + 0 + 2) = 2 $$
            The integral converges to exactly <strong>2</strong>. This is also equivalent to \( \Gamma(3) \), the Gamma
            function evaluated at 3.
        </p>
    </div>

    <div class="font-card style-overleaf">
        <span class="label">Style: Overleaf / Modern SaaS (Font: Montserrat)</span>
        <h2>Formatting Mathematical Proofs in LaTeX</h2>
        <p>
            When writing formal proofs in LaTeX, it is essential to align your logical connectives properly. We often
            use the `align` environment for multi-step deductions to ensure the equals signs form a clean vertical axis.
            Below is an example of a formal proof regarding limit definitions, often used in Real Analysis courses.
        </p>
        <p>
            <strong>Theorem:</strong> The limit of a sum is the sum of the limits.
            <br>
            <em>Proof:</em> Let \( \epsilon > 0 \) be given. We know that \( \lim_{x \to c} f(x) = L \) and \( \lim_{x
            \to c} g(x) = M \).
            This implies there exist \( \delta_1, \delta_2 > 0 \) such that:
            $$ 0 < |x - c| < \delta_1 \implies |f(x) - L| < \frac{\epsilon}{2} $$ $$ 0 < |x - c| < \delta_2 \implies
                |g(x) - M| < \frac{\epsilon}{2} $$ </p>
                <p>
                    Choose \( \delta = \min(\delta_1, \delta_2) \). Then for all \( x \) satisfying \( 0 < |x - c| <
                        \delta \), we can apply the Triangle Inequality: $$ \begin{aligned} |(f(x) + g(x)) - (L + M)|
                        &=|(f(x) - L) + (g(x) - M)| \\ &\leq |f(x) - L| + |g(x) - M| \\ &< \frac{\epsilon}{2} +
                        \frac{\epsilon}{2} \\ &=\epsilon \end{aligned} $$ </p>
                        <p>
                            Thus, by definition, \( \lim_{x \to c} [f(x) + g(x)] = L + M \). Q.E.D. Note how the
                            "Montserrat" font offers a wide, circular geometric feel that contrasts sharply with the
                            jagged math symbols.
                        </p>
    </div>

    <div class="font-card style-arxiv">
        <span class="label">Style: ArXiv (Font: Open Sans)</span>
        <h2>Abstract: Quantum Mechanics in a 1D Well</h2>
        <p>
            We investigate the behavior of a particle in a one-dimensional infinite potential well. The time-independent
            Schrödinger equation is given by \( \hat{H}\psi = E\psi \), where the Hamiltonian operator includes both
            kinetic and potential energy terms. This is a fundamental model for understanding quantum confinement.
        </p>
        <p>
            Inside the well (\( 0 < x < L \)), the potential \( V(x)=0 \), reducing the equation to a simple
                second-order differential equation: $$ -\frac{\hbar^2}{2m} \frac{d^2\psi}{dx^2}=E\psi \quad \implies
                \quad \frac{d^2\psi}{dx^2} + k^2\psi=0 $$ where we define the wave number \( k=\frac{\sqrt{2mE}}{\hbar}
                \). The general solution to this differential equation is of the form: $$ \psi(x)=A \sin(kx) + B
                \cos(kx) $$ </p>
                <p>
                    Applying boundary conditions \( \psi(0) = 0 \) and \( \psi(L) = 0 \), we find that \( B=0 \) and \(
                    kL = n\pi \) for integer \( n \). This leads to the quantization of energy levels, showing that
                    energy is not continuous at this scale:
                    $$ E_n = \frac{n^2 \pi^2 \hbar^2}{2mL^2}, \quad n = 1, 2, 3, \dots $$
                    The normalized wave functions are thus derived as \( \psi_n(x) =
                    \sqrt{\frac{2}{L}}\sin\left(\frac{n\pi x}{L}\right) \). These results are consistent with standard
                    quantum mechanical predictions and form the basis for particle-in-a-box models.
                </p>
    </div>

    <div class="font-card style-coursera">
        <span class="label">Style: Coursera (Font: Source Sans 3)</span>
        <h2>Machine Learning: Gradient Descent Optimization</h2>
        <p>
            In this module, we discuss how to minimize the cost function \( J(\theta) \) for linear regression. The goal
            is to find the parameters \( \theta_0, \theta_1 \) that minimize the squared error between our hypothesis \(
            h_\theta(x) \) and the actual data \( y \). This is the engine behind most supervised learning models.
        </p>
        <p>
            The Mean Squared Error (MSE) cost function is defined as:
            $$ J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2 $$
            where \( m \) is the number of training examples. To find the minimum, we use the <strong>Gradient
                Descent</strong> algorithm, which iteratively updates the parameters by taking steps proportional to the
            negative of the gradient.
        </p>
        <p>
            The update rule for a specific parameter \( \theta_j \) is:
            $$ \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta) $$
            Solving for the partial derivative, we get the specific update rule for linear regression:
            $$ \theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) - y^{(i)} \right)
            x_j^{(i)} $$
        </p>
        <p>
            Remember that \( \alpha \) is the learning rate. If \( \alpha \) is too small, convergence is slow. If \(
            \alpha \) is too large, the function may overshoot the minimum and fail to converge. Proper tuning of
            hyperparameters is essential for model performance.
        </p>
    </div>

    <div class="font-card style-libre">
        <span class="label">Style: LibreTexts (Font: Roboto)</span>
        <h2>Thermodynamics: The Ideal Gas Law</h2>
        <p>
            In this chapter, we explore the relationship between the macroscopic properties of gases. An <em>ideal
                gas</em> is a theoretical gas composed of many randomly moving point particles that are not subject to
            interparticle interactions. This approximation works well at high temperatures and low pressures.
        </p>
        <p>
            The state of an ideal gas is determined by the equation:
            $$ PV = nRT $$
        </p>
        <p>
            This equation can be derived from the kinetic theory of gases. If we consider the root-mean-square speed of
            particles, we find that the pressure \( P \) exerted by the gas is related to the average kinetic energy:
            $$ P = \frac{Nm \overline{v^2}}{3V} $$
            Since the average kinetic energy is proportional to temperature (\( \frac{1}{2}m\overline{v^2} =
            \frac{3}{2}k_B T \)), substituting this back yields the familiar ideal gas law.
        </p>
        <p>
            <strong>Example Problem:</strong><br>
            Calculate the volume occupied by 1.00 mol of an ideal gas at STP (Standard Temperature and Pressure, \(
            T=273.15 \, \text{K} \), \( P=100 \, \text{kPa} \)).
            $$ V = \frac{nRT}{P} = \frac{(1.00)(8.314)(273.15)}{10^5} \approx 0.0227 \, \text{m}^3 = 22.7 \, \text{L} $$
            Roboto provides a slightly more "mechanical" or "engineered" feel compared to Open Sans, fitting for
            technical textbooks.
        </p>
    </div>

    <div class="font-card style-serif">
        <span class="label">Style: The Academic Professor (Font: Bitter)</span>
        <h2>Number Theory: Euler's Totient Theorem</h2>
        <p>
            We conclude our discussion on modular arithmetic with a generalization of Fermat's Little Theorem. Fermat's
            theorem applies only when the modulus is prime. However, Euler introduced a function, \( \phi(n) \), which
            counts the positive integers less than \( n \) that are relatively prime to \( n \).
        </p>
        <p>
            <strong>Theorem:</strong> If \( a \) and \( n \) are coprime integers (i.e., \( \gcd(a, n) = 1 \)), then:
            $$ a^{\phi(n)} \equiv 1 \pmod n $$
        </p>
        <p>
            <em>Proof Sketch:</em> Let \( R = \{ r_1, r_2, \dots, r_{\phi(n)} \} \) be the set of integers less than \(
            n \) coprime to \( n \). If we multiply each element by \( a \), we get a new set \( S = \{ ar_1, ar_2,
            \dots, ar_{\phi(n)} \} \).
        </p>
        <p>
            Since \( \gcd(a, n)=1 \), the elements of \( S \) are just a permutation of the elements of \( R \) modulo
            \( n \). Therefore, the product of elements in \( S \) is congruent to the product of elements in \( R \):
            $$ \prod_{i=1}^{\phi(n)} (ar_i) \equiv \prod_{i=1}^{\phi(n)} r_i \pmod n $$
            $$ a^{\phi(n)} \left( \prod_{i=1}^{\phi(n)} r_i \right) \equiv \left( \prod_{i=1}^{\phi(n)} r_i \right)
            \pmod n $$
            Since the product term is coprime to \( n \), we can cancel it from both sides, leaving \( a^{\phi(n)}
            \equiv 1 \pmod n \). This theorem forms the mathematical backbone of the RSA encryption algorithm.
        </p>
    </div>

    <div class="font-card style-next">
        <span class="label">Style: Next.js / Vercel (Font: Geist / Inter Tight)</span>
        <h2>Rendering: Server Components & Performance</h2>
        <p>
            React Server Components allow you to write UI that can be rendered and optionally cached on the server. In
            Next.js, the rendering work is split by route segments to enable streaming. This architecture significantly
            impacts the time-complexity of data loading.
        </p>
        <p>
            <strong>Big O Complexity of SSR Waterfalls</strong><br>
            If a page requires \( N \) data fetches that are sequential (waterfalls), the total time to first byte
            (TTFB) is the sum of latencies plus the server render time:
            $$ T_{total} = T_{render} + \sum_{i=1}^{N} (L_{network}^{(i)} + L_{db}^{(i)}) $$
        </p>
        <p>
            However, utilizing <code>Promise.all()</code> or parallel routes, we can reduce the complexity to the
            maximum latency of the slowest request, rather than the sum:
            $$ T_{optimized} = T_{render} + \max(L_1, L_2, \dots, L_N) + \epsilon_{overhead} $$
        </p>
        <p>
            This shift from \( O(N) \) to \( O(1) \) relative to request count is why parallel data fetching is critical
            in the App Router. The tightness of this font (Inter with negative tracking) gives the text a dense, highly
            technical feel, mirroring the density of the code blocks usually found on these documentation pages.
        </p>
    </div>

    <div class="font-card style-clerk">
        <span class="label">Style: Clerk.com (Font: Inter)</span>
        <h2>Authentication: Password Hashing & Entropy</h2>
        <p>
            When storing user credentials, we never store plain text passwords. Instead, we store a hash resulting from
            a one-way cryptographic function. Clerk handles this complexity to ensure session security using
            industry-standard algorithms.
        </p>
        <p>
            <strong>Entropy and Hashing</strong><br>
            A secure hash function \( H(x) \) maps an input of arbitrary length to a fixed length output. Ideally, it
            should be computationally infeasible to invert:
            $$ H(password) = \text{digest} \quad \text{but} \quad H^{-1}(\text{digest}) \approx \text{Impossible} $$
        </p>
        <p>
            To prevent rainbow table attacks, we add a random "salt" \( S \) to the input before hashing. The stored
            value becomes:
            $$ \text{Stored Value} = H(\text{password} || S) $$
        </p>
        <p>
            Modern implementations use adaptive algorithms like <strong>Argon2id</strong> or <strong>bcrypt</strong>,
            where the work factor \( W \) can be tuned to resist hardware brute-force attacks. The cost to an attacker
            increases exponentially with the work factor:
            $$ T_{attack} \propto N_{attempts} \times 2^W $$
            This ensures that as hardware gets faster, we can simply increase \( W \) to maintain the same security
            margin. The cleanliness of the Inter font here ensures that security notices are readable and authoritative.
        </p>
    </div>

</body>

</html>